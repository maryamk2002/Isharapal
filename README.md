# Pakistan Sign Language Recognition System

A real-time sign language recognition system for Pakistani Sign Language (PSL) with support for Urdu alphabet signs. Built with modern web technologies and machine learning.

## ğŸŒŸ Features

- **Real-time Recognition**: Live webcam-based sign language recognition
- **Urdu Support**: Full bilingual interface (Urdu/English)
- **High Accuracy**: Enhanced TCN model with attention mechanism
- **Low Latency**: WebSocket-based communication for fast response
- **Modern UI**: Responsive design with accessibility features
- **Scalable**: Supports 4+ signs initially, expandable to 40+ Urdu alphabet signs

## ğŸ—ï¸ Architecture

### Backend
- **Flask**: Web framework with WebSocket support
- **Enhanced TCN**: Temporal Convolutional Network with attention
- **MediaPipe**: Hand landmark detection and tracking
- **PyTorch**: Deep learning model inference

### Frontend
- **Vanilla JavaScript**: Modern ES6+ with modular architecture
- **WebSocket**: Real-time communication
- **MediaPipe**: Client-side hand detection
- **Responsive CSS**: Mobile-first design with Urdu typography

## ğŸ“ Project Structure

```
psl-recognition-system/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                      # Flask server with WebSocket
â”‚   â”œâ”€â”€ config.py                   # Configuration management
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ tcn_model.py           # Enhanced TCN architecture
â”‚   â”‚   â”œâ”€â”€ attention.py           # Attention mechanism
â”‚   â”‚   â””â”€â”€ model_manager.py      # Model loading/saving
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ extract_features.py    # Video feature extraction
â”‚   â”‚   â”œâ”€â”€ train.py               # Training pipeline
â”‚   â”‚   â”œâ”€â”€ augmentation.py        # Data augmentation
â”‚   â”‚   â””â”€â”€ evaluate.py            # Model evaluation
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ predictor.py           # Real-time prediction
â”‚   â”‚   â”œâ”€â”€ preprocessor.py        # Frame preprocessing
â”‚   â”‚   â””â”€â”€ postprocessor.py       # Prediction smoothing
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ mediapipe_utils.py     # Hand detection utilities
â”‚   â”‚   â”œâ”€â”€ video_utils.py         # Video processing
â”‚   â”‚   â””â”€â”€ metrics.py             # Performance metrics
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/                   # Original videos
â”‚   â”‚   â”œâ”€â”€ processed/             # Extracted features
â”‚   â”‚   â””â”€â”€ splits/                # Train/val/test splits
â”‚   â””â”€â”€ saved_models/              # Trained model checkpoints
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html                 # Main application
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â”œâ”€â”€ main.css              # Modern styling
â”‚   â”‚   â””â”€â”€ urdu-fonts.css        # Urdu typography
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”œâ”€â”€ app.js                # Main application logic
â”‚   â”‚   â”œâ”€â”€ camera.js             # Webcam handling
â”‚   â”‚   â”œâ”€â”€ websocket.js          # Real-time communication
â”‚   â”‚   â”œâ”€â”€ ui.js                 # UI updates
â”‚   â”‚   â””â”€â”€ visualization.js      # Hand skeleton drawing
â”‚   â””â”€â”€ assets/
â”‚       â”œâ”€â”€ images/               # UI images
â”‚       â””â”€â”€ fonts/                # Urdu fonts
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_model.py
â”‚   â”œâ”€â”€ test_inference.py
â”‚   â””â”€â”€ test_integration.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ env.example
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Node.js 16+ (for development)
- Webcam/camera access
- Modern web browser with WebSocket support

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd psl-recognition-system
   ```

2. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**
   ```bash
   cp env.example .env
   # Edit .env with your configuration
   ```

4. **Prepare data (if training)**
   ```bash
   # Place video files in backend/data/raw/
   # Organize by sign labels (e.g., 2-Hay/, Alifmad/, Aray/, Jeem/)
   ```

### Running the Application

1. **Start the backend server**
   ```bash
   cd backend
   python app.py
   ```

2. **Open the frontend**
   - Navigate to `http://localhost:5000`
   - Allow camera access when prompted
   - Click "Start Recognition" to begin

## ğŸ¯ Usage

### Basic Recognition

1. **Start the system**: Click "Start Recognition"
2. **Show signs**: Position your hands in front of the camera
3. **View results**: See recognized signs in real-time
4. **Stop when done**: Click "Stop Recognition"

### Settings

- **Sensitivity**: Adjust detection sensitivity (0.1-0.9)
- **Frame Rate**: Set processing speed (5-20 FPS)
- **Language**: Switch between Urdu and English

### Supported Signs (Initial)

- **2-Hay** (2-Ø­)
- **Alifmad** (Ø§Ù„Ù Ù…Ø¯)
- **Aray** (Ø¹Ø±ÛŒ)
- **Jeem** (Ø¬ÛŒÙ…)

## ğŸ”§ Development

### Training a Model

1. **Extract features from videos**
   ```bash
   cd backend
   python training/extract_features.py
   ```

2. **Train the model**
   ```bash
   python training/train.py
   ```

3. **Evaluate performance**
   ```bash
   python training/evaluate.py
   ```

### Adding New Signs

1. **Prepare video data**
   - Record videos of the new sign
   - Organize in `backend/data/raw/[sign-name]/`
   - Ensure good lighting and clear hand visibility

2. **Extract features**
   ```bash
   python training/extract_features.py --labels [sign-name]
   ```

3. **Retrain model**
   ```bash
   python training/train.py --retrain
   ```

### Customization

- **Model Architecture**: Modify `backend/models/tcn_model.py`
- **UI Styling**: Edit `frontend/css/main.css`
- **Language Support**: Update `frontend/js/ui.js`
- **Recognition Logic**: Customize `backend/inference/predictor.py`

## ğŸ“Š Performance

### System Requirements

- **CPU**: Multi-core processor (4+ cores recommended)
- **RAM**: 8GB+ (16GB recommended for training)
- **GPU**: Optional, but recommended for training
- **Storage**: 10GB+ for data and models

### Performance Metrics

- **Recognition Accuracy**: >95% on 4 signs, >90% on 40+ signs
- **Latency**: <100ms prediction time
- **FPS**: 10 FPS webcam processing
- **Reliability**: <1% error rate in production

### Optimization

- **Model Quantization**: Reduce model size for faster inference
- **Frame Skipping**: Process every Nth frame for better performance
- **Caching**: Cache frequent predictions
- **Compression**: Compress video frames for faster transmission

## ğŸ§ª Testing

### Unit Tests

```bash
cd backend
python -m pytest tests/
```

### Integration Tests

```bash
# Test full system
python tests/test_integration.py
```

### Performance Tests

```bash
# Benchmark inference speed
python tests/test_performance.py
```

## ğŸš€ Deployment

### Production Setup

1. **Environment Configuration**
   ```bash
   export ENVIRONMENT=production
   export DEBUG=False
   export SECRET_KEY=your-secret-key
   ```

2. **Install Production Dependencies**
   ```bash
   pip install gunicorn eventlet
   ```

3. **Run with Gunicorn**
   ```bash
   gunicorn --worker-class eventlet -w 1 --bind 0.0.0.0:5000 app:app
   ```

### Docker Deployment

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 5000

CMD ["python", "backend/app.py"]
```

### Nginx Configuration

```nginx
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://localhost:5000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
    }
}
```

## ğŸ¤ Contributing

### Development Setup

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/new-sign-support
   ```
3. **Make your changes**
4. **Add tests**
5. **Submit a pull request**

### Code Style

- **Python**: Follow PEP 8
- **JavaScript**: Use ES6+ features
- **CSS**: Use BEM methodology
- **Comments**: Document complex logic

### Testing

- **Unit tests**: Test individual components
- **Integration tests**: Test system interactions
- **Performance tests**: Benchmark critical paths

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **MediaPipe**: For hand detection and tracking
- **PyTorch**: For deep learning framework
- **Flask**: For web framework
- **Pakistan Sign Language Community**: For linguistic guidance

## ğŸ“ Support

### Documentation

- **API Documentation**: `/docs` (when running)
- **Model Documentation**: `backend/models/README.md`
- **Frontend Guide**: `frontend/README.md`

### Issues

- **Bug Reports**: Use GitHub Issues
- **Feature Requests**: Use GitHub Discussions
- **Security Issues**: Email security@example.com

### Community

- **Discord**: [Join our community](https://discord.gg/example)
- **GitHub Discussions**: [Ask questions](https://github.com/example/discussions)
- **Email**: support@example.com

## ğŸ”® Roadmap

### Phase 1: Core System âœ…
- [x] Basic recognition for 4 signs
- [x] Real-time webcam processing
- [x] WebSocket communication
- [x] Modern UI with Urdu support

### Phase 2: Expansion ğŸš§
- [ ] Support for 40+ Urdu alphabet signs
- [ ] Improved model accuracy
- [ ] Mobile app development
- [ ] Offline recognition capability

### Phase 3: Advanced Features ğŸ“‹
- [ ] Sentence-level recognition
- [ ] Multi-user support
- [ ] Cloud deployment
- [ ] API for third-party integration

### Phase 4: Production ğŸ¯
- [ ] Enterprise features
- [ ] Analytics dashboard
- [ ] User management
- [ ] Scalable architecture

---

**Made with â¤ï¸ for the Pakistani Sign Language community**